{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3775b8e-a02e-4295-98f0-d32d3b4dd430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, ByteType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39097c4f-7a3d-4de7-8990-59e8fe383848",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b4c5d4d-9693-4c3a-8421-a27b35ab2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join(\"data\", \"train.csv\")\n",
    "TEST_PATH = os.path.join(\"data\", \"test.csv\")\n",
    "PROC_CNT = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd1d3c78-45b8-4e2f-b4a0-57db0a2ea662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/10 21:25:37 WARN Utils: Your hostname, pc resolves to a loopback address: 127.0.1.1; using 192.168.0.101 instead (on interface eno1)\n",
      "22/12/10 21:25:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/10 21:25:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder.appName(\"task_5\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")\n",
    "    .config(\"spark.driver.cores\", \"4\")\n",
    "    .config(\"spark.driver.maxResultSize\", \"12g\")\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .config(\"spark.executor.cores\", \"4\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4396b77a-bab7-4c6d-9a59-c0c7f9cc0816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- comment_text: string (nullable = true)\n",
      " |-- toxic: byte (nullable = true)\n",
      " |-- severe_toxic: byte (nullable = true)\n",
      " |-- obscene: byte (nullable = true)\n",
      " |-- threat: byte (nullable = true)\n",
      " |-- insult: byte (nullable = true)\n",
      " |-- identity_hate: byte (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "        StructField(\"id\", StringType()),\n",
    "        StructField(\"comment_text\", StringType()),\n",
    "        StructField(\"toxic\", ByteType()),\n",
    "        StructField(\"severe_toxic\", ByteType()),\n",
    "        StructField(\"obscene\", ByteType()),\n",
    "        StructField(\"threat\", ByteType()),\n",
    "        StructField(\"insult\", ByteType()),\n",
    "        StructField(\"identity_hate\", ByteType())\n",
    "])\n",
    "train_sdf = spark.read.option(\"multiline\",True).csv(TRAIN_PATH, header=True, quote=\"\\\"\", escape=\"\\\"\", sep=',', schema=schema)\n",
    "train_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8410ac23-0a3b-4258-9d3d-55ffe5a91b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|0000997932d777bf|Explanation\\nWhy ...|    0|           0|      0|     0|     0|            0|\n",
      "|000103f0d9cfb60f|D'aww! He matches...|    0|           0|      0|     0|     0|            0|\n",
      "|000113f07ec002fd|Hey man, I'm real...|    0|           0|      0|     0|     0|            0|\n",
      "|0001b41b1c6bb37e|\"\\nMore\\nI can't ...|    0|           0|      0|     0|     0|            0|\n",
      "|0001d958c54c6e35|You, sir, are my ...|    0|           0|      0|     0|     0|            0|\n",
      "|00025465d4725e87|\"\\n\\nCongratulati...|    0|           0|      0|     0|     0|            0|\n",
      "|0002bcb3da6cb337|COCKSUCKER BEFORE...|    1|           1|      1|     0|     1|            0|\n",
      "|00031b1e95af7921|Your vandalism to...|    0|           0|      0|     0|     0|            0|\n",
      "|00037261f536c51d|Sorry if the word...|    0|           0|      0|     0|     0|            0|\n",
      "|00040093b2687caa|alignment on this...|    0|           0|      0|     0|     0|            0|\n",
      "|0005300084f90edc|\"\\nFair use ratio...|    0|           0|      0|     0|     0|            0|\n",
      "|00054a5e18b50dd4|bbq \\n\\nbe a man ...|    0|           0|      0|     0|     0|            0|\n",
      "|0005c987bdfc9d4b|Hey... what is it...|    1|           0|      0|     0|     0|            0|\n",
      "|0006f16e4e9f292e|Before you start ...|    0|           0|      0|     0|     0|            0|\n",
      "|00070ef96486d6f9|Oh, and the girl ...|    0|           0|      0|     0|     0|            0|\n",
      "|00078f8ce7eb276d|\"\\n\\nJuelz Santan...|    0|           0|      0|     0|     0|            0|\n",
      "|0007e25b2121310b|Bye! \\n\\nDon't lo...|    1|           0|      0|     0|     0|            0|\n",
      "|000897889268bc93|REDIRECT Talk:Voy...|    0|           0|      0|     0|     0|            0|\n",
      "|0009801bd85e5806|The Mitsurugi poi...|    0|           0|      0|     0|     0|            0|\n",
      "|0009eaea3325de8c|Don't mean to bot...|    0|           0|      0|     0|     0|            0|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6621595-23f8-455a-92db-8be5f79af5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "|0000997932d777bf|explanation why t...|    0|           0|      0|     0|     0|            0|\n",
      "|000103f0d9cfb60f|d'aww! he matches...|    0|           0|      0|     0|     0|            0|\n",
      "|000113f07ec002fd|hey man, i'm real...|    0|           0|      0|     0|     0|            0|\n",
      "|0001b41b1c6bb37e|more i can't make...|    0|           0|      0|     0|     0|            0|\n",
      "|0001d958c54c6e35|you, sir, are my ...|    0|           0|      0|     0|     0|            0|\n",
      "|00025465d4725e87|congratulations f...|    0|           0|      0|     0|     0|            0|\n",
      "|0002bcb3da6cb337|cocksucker before...|    1|           1|      1|     0|     1|            0|\n",
      "|00031b1e95af7921|your vandalism to...|    0|           0|      0|     0|     0|            0|\n",
      "|00037261f536c51d|sorry if the word...|    0|           0|      0|     0|     0|            0|\n",
      "|00040093b2687caa|alignment on this...|    0|           0|      0|     0|     0|            0|\n",
      "|0005300084f90edc|fair use rational...|    0|           0|      0|     0|     0|            0|\n",
      "|00054a5e18b50dd4|bbq   be a man an...|    0|           0|      0|     0|     0|            0|\n",
      "|0005c987bdfc9d4b|hey... what is it...|    1|           0|      0|     0|     0|            0|\n",
      "|0006f16e4e9f292e|before you start ...|    0|           0|      0|     0|     0|            0|\n",
      "|00070ef96486d6f9|oh, and the girl ...|    0|           0|      0|     0|     0|            0|\n",
      "|00078f8ce7eb276d|juelz santanas ag...|    0|           0|      0|     0|     0|            0|\n",
      "|0007e25b2121310b|bye!   don't look...|    1|           0|      0|     0|     0|            0|\n",
      "|000897889268bc93|redirect talk:voy...|    0|           0|      0|     0|     0|            0|\n",
      "|0009801bd85e5806|the mitsurugi poi...|    0|           0|      0|     0|     0|            0|\n",
      "|0009eaea3325de8c|don't mean to bot...|    0|           0|      0|     0|     0|            0|\n",
      "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sdf = (\n",
    "    train_sdf\n",
    "    .withColumn(\"comment_text\", F.lower(\"comment_text\"))\n",
    "    .withColumn(\"comment_text\", F.regexp_replace(F.col(\"comment_text\"), \"[\\n\\\"]\", \" \"))\n",
    "    .withColumn(\"comment_text\", F.trim(F.col(\"comment_text\")))\n",
    ")\n",
    "train_sdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46325aa0-4533-48c3-8803-fddab54b4a61",
   "metadata": {},
   "source": [
    "## 1. HashingTF и IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d099612e-56c0-481c-b18a-acf04492db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_model(col_name: str) -> CrossValidator:\n",
    "    hashing_tf = HashingTF(inputCol=\"remover_out\", outputCol=\"tf_out\")\n",
    "    log_reg = LogisticRegression(featuresCol=\"idf_out\", labelCol=col_name)\n",
    "    pipe = Pipeline(\n",
    "        stages=[\n",
    "            Tokenizer(inputCol=\"comment_text\", outputCol=\"tokenizer_out\"),\n",
    "            (\n",
    "                StopWordsRemover(\n",
    "                    stopWords=StopWordsRemover.loadDefaultStopWords(\"english\"),\n",
    "                    inputCol=\"tokenizer_out\",\n",
    "                    outputCol=\"remover_out\",\n",
    "                )\n",
    "            ),\n",
    "            hashing_tf,\n",
    "            IDF(inputCol=\"tf_out\", outputCol=\"idf_out\"),\n",
    "            log_reg\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    grid = (\n",
    "        ParamGridBuilder()\n",
    "        # .addGrid(log_reg.maxIter, [100, 200])\n",
    "        .baseOn({log_reg.maxIter: 100})\n",
    "        .addGrid(log_reg.regParam, [0.03, 0.1, 1.0])\n",
    "        .addGrid(log_reg.elasticNetParam, [0.05, 0.1, 1.0])\n",
    "        .addGrid(hashing_tf.numFeatures, [1000, 10_000, 20_000])\n",
    "        .build()\n",
    "    )\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=col_name)\n",
    "    cv_model = CrossValidator(\n",
    "        estimator=pipe,\n",
    "        estimatorParamMaps=grid,\n",
    "        evaluator=evaluator,\n",
    "        parallelism=PROC_CNT\n",
    "    )\n",
    "    \n",
    "    return cv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca4b10ea-9c78-4b8a-945f-ecdd8fb04448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 6/6 [30:26<00:00, 304.38s/it, identity_hate]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.5 s, sys: 17 s, total: 1min 14s\n",
      "Wall time: 30min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_cols = [col for col in train_sdf.columns if not col in [\"id\", \"comment_text\"]]\n",
    "pbar = tqdm(target_cols)\n",
    "results = {}\n",
    "\n",
    "for target_col in pbar:\n",
    "    pbar.set_postfix_str(target_col)\n",
    "    # Free memory\n",
    "    spark.catalog.clearCache()\n",
    "    model = get_cv_model(target_col)\n",
    "    model = model.fit(train_sdf)\n",
    "    results[target_col] = {\n",
    "        'model': model,\n",
    "        'score': max(model.avgMetrics),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a84ab5b6-bc21-4a04-9220-de5573918f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: toxic\n",
      "Score: 0.8937447870122099\n",
      "\n",
      "Label: severe_toxic\n",
      "Score: 0.9247631422657824\n",
      "\n",
      "Label: obscene\n",
      "Score: 0.9053453986836191\n",
      "\n",
      "Label: threat\n",
      "Score: 0.7556043304167565\n",
      "\n",
      "Label: insult\n",
      "Score: 0.9071599438837219\n",
      "\n",
      "Label: identity_hate\n",
      "Score: 0.8330782953044618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in results:\n",
    "    print(f\"Label: {col}\\nScore: {results[col]['score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06e0d35a-58b3-4306-9185-abb25e62f11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For toxic numFeatures: 20000\n",
      "For severe_toxic numFeatures: 20000\n",
      "For obscene numFeatures: 20000\n",
      "For threat numFeatures: 20000\n",
      "For insult numFeatures: 20000\n",
      "For identity_hate numFeatures: 20000\n"
     ]
    }
   ],
   "source": [
    "for col in results:\n",
    "    cv_model = results['toxic']['model']\n",
    "    params = cv_model.getEstimatorParamMaps()[np.argmax(cv_model.avgMetrics)]\n",
    "    \n",
    "    for param in params:\n",
    "        if param.name == 'numFeatures':\n",
    "            print(f\"For {col} numFeatures: {params[param]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76f7d23d-4b33-4aed-9a67-4ad223d380e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a538bdf-443c-429b-92c0-03e373474b37",
   "metadata": {},
   "source": [
    "Вывод: numFeatures лучше выбирать большим. Попытки ставить больше 20 000 приводили к тому, что не хватало памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee04213-c165-4c69-bed8-feace7c63429",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6d6073-dbc7-4eef-8dce-71eed81a288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_model(col_name: str) -> CrossValidator:\n",
    "    w2v = Word2Vec(inputCol=\"remover_out\", outputCol=\"w2v\")\n",
    "    log_reg = LogisticRegression(featuresCol=\"w2v\", labelCol=col_name)\n",
    "    pipe = Pipeline(\n",
    "        stages=[\n",
    "            Tokenizer(inputCol=\"comment_text\", outputCol=\"tokenizer_out\"),\n",
    "            (\n",
    "                StopWordsRemover(\n",
    "                    stopWords=StopWordsRemover.loadDefaultStopWords(\"english\"),\n",
    "                    inputCol=\"tokenizer_out\",\n",
    "                    outputCol=\"remover_out\",\n",
    "                )\n",
    "            ),\n",
    "            w2v,\n",
    "            log_reg\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    grid = (\n",
    "        ParamGridBuilder()\n",
    "        .baseOn({log_reg.maxIter: 100})\n",
    "        .addGrid(log_reg.regParam, [0.03, 0.1])\n",
    "        .addGrid(w2v.windowSize, [3, 5])\n",
    "        .addGrid(w2v.vectorSize, [20, 30, 50])\n",
    "        .build()\n",
    "    )\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=col_name)\n",
    "    cv_model = CrossValidator(\n",
    "        estimator=pipe,\n",
    "        estimatorParamMaps=grid,\n",
    "        evaluator=evaluator,\n",
    "        parallelism=PROC_CNT\n",
    "    )\n",
    "    \n",
    "    return cv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc0a140c-bee0-4a27-8d11-46dfc8e983da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 6/6 [58:43<00:00, 587.22s/it, identity_hate]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.1 s, sys: 9.14 s, total: 38.2 s\n",
      "Wall time: 58min 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_cols = [col for col in train_sdf.columns if not col in [\"id\", \"comment_text\"]]\n",
    "pbar = tqdm(target_cols)\n",
    "results = {}\n",
    "\n",
    "for target_col in pbar:\n",
    "    pbar.set_postfix_str(target_col)\n",
    "    # Free memory\n",
    "    spark.catalog.clearCache()\n",
    "    model = get_cv_model(target_col)\n",
    "    model = model.fit(train_sdf)\n",
    "    results[target_col] = {\n",
    "        'model': model,\n",
    "        'score': max(model.avgMetrics),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d2f9a7-b65f-4994-a6a1-c091e537d5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: toxic\n",
      "Score: 0.9314225553711087\n",
      "\n",
      "Label: severe_toxic\n",
      "Score: 0.9763162168260412\n",
      "\n",
      "Label: obscene\n",
      "Score: 0.9539944046334209\n",
      "\n",
      "Label: threat\n",
      "Score: 0.9387554924296667\n",
      "\n",
      "Label: insult\n",
      "Score: 0.942575134980553\n",
      "\n",
      "Label: identity_hate\n",
      "Score: 0.9438553193847002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in results:\n",
    "    print(f\"Label: {col}\\nScore: {results[col]['score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a9ad7bb-9109-42c5-9e26-217c43582ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6140a86-b4a7-4c53-b879-c82597ba0d05",
   "metadata": {},
   "source": [
    "Вывод: сравнительно с предыдущим подходом результаты улучшились примерно на 4%, не смотря на то что для экономии ресурсов использовалось кодирование w2v в вектора достаточно небольшой длины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea5be6-aab3-4a3c-ad80-51203d24ccff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
