# Машинное обучение на больших данных

### Task 1

- Развертывание локального кластера Hadoop в конфигурации 1 NN, 3 DN + NM, 1 RM, 1 History server
- Написание map reduce для подсчета среднего и дисперсии

### Task 2

- Развертывание локально Hive и подключение Hue, Zeppelin
- Загрузить данные в Hive и найти следующие значения:
1. Исполнителя с максимальным числом скрабблов
2. Самый популярный тэг на ластфм
3. Самые популярные исполнители 10 самых популярных тэгов ластфм
4. Любой другой инсайт

### Task 3

- Реализовать алгоритм линейной регрессии на Scala с использованием библиотеки Breeze

### Task 5

- С помощью pyspark.ml реализовать пайплайн подсчета HashingTF IDF и Word2Vec
